{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating RL environment from scratch using OpenAI\n",
    "\n",
    "An environment contains all necessary functionalities to deploy an RL agent so that it can perform actions from observations and recieve rewards. \n",
    "- observations: included in `observation_space`; data provided to make informed decisions, e.g. open price, high, low, close, and daily volume, as well as portfolio status such as account balance, current stock positions, and current profit.\n",
    "- actions: defined in `action_space`; buy, sell or hold a specific percentage\n",
    "- rewards: defined as discounted account balance to incentivize the agent to maintain profits over longer period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "max_share_num = 2147483647\n",
    "max_share_price = 5000\n",
    "max_steps = 1000\n",
    "init_bal = 10000\n",
    "\n",
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"Trading Environment that follows gym interface\"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, assetType, df, dayRange = 5):\n",
    "        '''\n",
    "        define action and observaton space as gym.spaces objects \n",
    "        input:\n",
    "            assetType: \n",
    "            a string; type of assets that the agent trades with; \n",
    "            choose between 'stock', 'FX', 'options'\n",
    "            \n",
    "            df:\n",
    "            a pandas dataframe containing data \n",
    "            \n",
    "            dayRange:\n",
    "            an integet; specifies the number of days that agent uses to determine actions\n",
    "        '''\n",
    "        super(TradingEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.dayRange = dayRange\n",
    "        \n",
    "        if assetType == 'stock':\n",
    "            # actions include buy, sell, or hold x% \n",
    "            self.action_space = spaces.Box(low=np.array([0, 0]), \n",
    "                                           high=np.array([3, 1]), \n",
    "                                           dtype=np.float16)\n",
    "            # observations include prices containing the open-high-low-close (OHLC) values for the last five days\n",
    "            self.observation_space = spaces.Box(low=0, high=1, \n",
    "                                                shape=(self.dayRange+1, self.dayRange+1), \n",
    "                                                dtype=np.float16)\n",
    "\n",
    "    \n",
    "  \n",
    "    def reset(self):\n",
    "        \n",
    "        '''\n",
    "        initialise or reset an existing environment's state:\n",
    "            balance, net_worth and max net worth are initial account balance;\n",
    "            intial timestep is randomly chosen within the data timeframe\n",
    "        \n",
    "        '''\n",
    "            \n",
    "        self.balance = init_bal\n",
    "        self.max_bal = init_bal\n",
    "        self.net_worth = init_bal\n",
    "        self.max_net_worth = init_bal\n",
    "        self.shares_held = 0\n",
    "        self.avg_cost = 0\n",
    "        self.total_shares_sold = 0\n",
    "        self.total_sales_value = 0\n",
    "        self.current_step = np.random.randint(0, self.df.shape[0] - (self.dayRange+1))\n",
    "        return self._next_observation()\n",
    "    \n",
    "    def _take_action(self, action):\n",
    "        '''\n",
    "        execute a given action for one time step within the environment \n",
    "        input:\n",
    "            action:\n",
    "            an np.array of shape 2;\n",
    "            action[0] is a float between 0 to 3 that specifies whether buy (0~1), sell(1~2) or hold(2~3);\n",
    "            action[1] is a float between 0 to 1 that specifies the bbuy/sell amount in %\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        # set the current price to be a random price between open and close price within the timestep\n",
    "        current_price = random.uniform(\n",
    "            self.df.loc[self.current_step, \"Open\"],\n",
    "            self.df.loc[self.current_step, \"Close\"])\n",
    "        \n",
    "        action_type = action[0] \n",
    "        amount = action[1]\n",
    "        \n",
    "        if action_type < 1:\n",
    "            '''\n",
    "            buy x% of balance in shares:\n",
    "            1. calculate total possible number of shares from the current balance and current price\n",
    "            2. buy x% of the total possible number of shares\n",
    "            3. calculate cost of buying the shares\n",
    "            4. update balance with buying cost\n",
    "            5. update previous average buying cost with the new buying cost \n",
    "            6. update number of shares held \n",
    "            \n",
    "            '''\n",
    "           \n",
    "            total_possible = self.balance / current_price \n",
    "            shares_bought = total_possible * amount\n",
    "            buying_cost = shares_bought * current_price\n",
    "            self.balance -= buying_cost\n",
    "            \n",
    "            prev_cost = self.avg_cost * self.shares_held\n",
    "            self.avg_cost = (prev_cost + buying_cost) / (self.shares_held + shares_bought)\n",
    "            self.shares_held += shares_bought\n",
    "        \n",
    "        elif actionType < 2:\n",
    "            '''\n",
    "            sell x% of shares held:\n",
    "            1. sell x% of the total number of shares held\n",
    "            2. update balance with selling revenue\n",
    "            3. update number of shares held \n",
    "            4. update total number of shares sold  \n",
    "            5. update total value of share sold\n",
    "            '''\n",
    "\n",
    "            shares_sold = self.shares_held * amount \n",
    "            self.balance += shares_sold * current_price\n",
    "            self.shares_held -= shares_sold\n",
    "            self.total_shares_sold += shares_sold\n",
    "            self.total_sales_value += shares_sold * current_price\n",
    "        \n",
    "        \n",
    "        # update portfolio net worth \n",
    "        self.net_worth = self.balance + self.shares_held * current_price\n",
    "        \n",
    "        # update maximum net worth\n",
    "        if self.net_worth > self.max_net_worth: self.max_net_worth = self.net_worth\n",
    "            \n",
    "        # update maximum balance \n",
    "        if self.balance > self.max_bal: self.max_bal = self.balance \n",
    "            \n",
    "    \n",
    "    def _next_observation(self):\n",
    "        \n",
    "        '''\n",
    "        given the current timestep and action, get the OHLC data from the last 5 days, normalise it, and appends portfolio's status\n",
    "        \n",
    "        '''\n",
    "\n",
    "        \n",
    "        frame = np.array([\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'Open'].values / max_share_price,\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'High'].values / max_share_price,\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'Low'].values / max_share_price,\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'Close'].values / max_share_price,\n",
    "            self.df.loc[self.current_step: self.current_step + 5, 'Volume'].values / max_share_num\n",
    "        ])\n",
    "\n",
    "        obs = np.append(frame, \n",
    "                        [[self.balance / self.max_bal,\n",
    "                          self.max_net_worth / self.max_net_worth,\n",
    "                          self.shares_held / max_share_num,\n",
    "                          self.avg_cost / max_share_price,\n",
    "                          self.total_shares_sold / max_share_num,\n",
    "                          self.total_sales_value / (max_share_num * max_share_price)\n",
    "                         ]], axis=0)\n",
    "        return obs\n",
    "    \n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        '''\n",
    "        given the action taken, update rewards, observations, and whether it's terminated, i.e. negative balance\n",
    "        '''\n",
    "        self._take_action(action)\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        # discount the account balance \n",
    "        delay_modifier = (self.current_step / max_steps)\n",
    "        reward = self.balance * delay_modifier\n",
    "        \n",
    "        # terminate when net worh is below 0 or timestep exceeds timeframe\n",
    "        done = self.net_worth <= 0 or self.current_step > self.df.shape[0] - (self.dayRange+1)\n",
    "        \n",
    "        obs = self._next_observation()\n",
    "        return obs, reward, done, {}\n",
    "        \n",
    "        \n",
    "    def render(self, mode='human', close=False):\n",
    "        # Render the environment to the screen\n",
    "        profit = self.net_worth - init_bal\n",
    "             \n",
    "        print(f'Step: {self.current_step}')    \n",
    "        print(f'Balance: {self.balance}')      \n",
    "        print(f'Shares held: {self.shares_held}(Total sold: {self.total_shares_sold})')      \n",
    "        print(f'Avg cost for held shares: {self.avg_cost}(Total sales value: {self.total_sales_value})')        \n",
    "        print(f'Net worth: {self.net_worth}(Max net worth: {self.max_net_worth})')\n",
    "        print(f'Profit: {profit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsa",
   "language": "python",
   "name": "mlsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
